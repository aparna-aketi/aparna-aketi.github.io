---
layout: post
title: Stochastic Gradient Push (SGP)
tags: Decentralized_Learning
---

In the previous post, we discussed a baseline decentralized learning algorithm known as [D-PSGD](https://arxiv.org/pdf/1705.09056.pdf). One of the bottlenecks of D-PSGD is that it requires the connectivity across the agents to be static and undirected. However, in practical scenarios, the connectivity across the agents could change with time. This demands a decentralized algorithm that can converge for time-varying and directed graph structures. [Stochastic Gradient Push](https://arxiv.org/pdf/1811.10792.pdf) achieves this by combining [PushSum](https://ieeexplore.ieee.org/document/1238221) with stochastic gradient updates. 
The main difference between D-PSGD and SGP is that SGP communicates an additional parameter called ps-weight (PushSum weight) along with model parameters among the neighboring agents. ps-weight keeps track of the total weightage of the neighborhood in the current iteration. 

Let's first understand SGP with a simple example. Consider an agent-$i$ with neighbors $j,k$. In D-PSGD, agent-$i$ assumes that it always receives the information from $j,k$, and the mixing is a properly weighted average (row-stochastic nature of mixing matrix). In particular, agent-$i$ simply multiplies its information with self-weight ($w_{ii}x_i$) and combines it with the information stored in receiving buffer ($w_{ij}x_j+w_{ik}x_k$). Here, agent-$i$ updates $x_i = w_{ii}x_i+w_{ij}x_j+w_{ik}x_k$ assuming that receiving buffer always has information from $j,k$ and $w_{ii}+w_{ij}+w_{ik}=1$. This assumption breaks when we have time-varying and/or directed graphs. To circumvent this, SGP sends the weight values along with the required information. Now back to the simple example and with SGP, agent-$i$ has two receiving buffers: buffer1 for the required information ($w_{ij}x_j+w_{ik}x_k$) and buffer2 for weights ($w_{ij}+w_{ik}$). To update, agent-$i$ adds the weighted self-information to the received information in buffer1 and self-weight to buffer2. Finally, the update for agent-$i$ is $x_i = (w_{ii}x_i+w_{ij}x_j+w_{ik}x_k)/(w_{ii}+w_{ij}+w_{ik})$. 
Let's say agent-$j$'s connection to $i$ is broken for some reason. In this case, D-PSGD's update will be $x_i = w_{ii}x_i+w_{ik}x_k$ whereas for SGP $x_i = (w_{ii}x_i+w_{ik}x_k)/(w_{ii}+w_{ik})$. Here, we can clearly see that it's a proper weighted average in the case of SGP update but not for D-PSGD. From this, we can conclude that SGP converges for time-varying and directed graphs.

**SGP Algorithm:**

At the beginning of the training, all the agents are initialized to the same model parameters and hyperparameters are synchronized. The pseudo-code for D-PSGD is given below.
